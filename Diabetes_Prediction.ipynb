{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2b72fd",
   "metadata": {
    "id": "da2b72fd"
   },
   "source": [
    "## Early stage Classification of Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3db8ae07",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#importing the packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive Agg backend\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a92cc932",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ee896d69",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"Running in Colab. Please upload diabetes.csv\")\n",
    "    uploaded = files.upload()  # Upload diabetes.csv\n",
    "    data = pd.read_csv('diabetes.csv')\n",
    "except ImportError:\n",
    "    # For local Jupyter: Load from path\n",
    "    data = pd.read_csv(r\"C:\\Users\\kk382\\OneDrive\\Desktop\\dl_project\\Diabetes_prediction\\diabetes.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define column names\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', \n",
    "           'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "\n",
    "# Verify column names\n",
    "if list(data.columns) != columns:\n",
    "    raise ValueError(f\"Expected columns {columns}, but got {list(data.columns)}\")\n",
    "\n",
    "# Visualize class distribution\n",
    "gendis = px.histogram(data, x='Outcome', color='Outcome', title=\"Positive/Negative count Vs Outcome\")\n",
    "gendis.write_html(\"diabetes_class_distribution.html\")  # Save Plotly figure to file\n",
    "\n",
    "# Handle missing values\n",
    "missing_columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "data[missing_columns] = data[missing_columns].replace(0, np.nan)\n",
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9020e7b1",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop('Outcome', axis=1).values\n",
    "y = data['Outcome'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4c964d36",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eed2aef8",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# Implement Proximity-Weighted Synthetic Oversampling (ProWSyn)\n",
    "def prowsyn(X, y, beta=2.0, K=5, L=3, theta=0.5):\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    minority_class = 1\n",
    "    majority_class = 0\n",
    "    min_indices = np.where(y == minority_class)[0]\n",
    "    maj_indices = np.where(y == majority_class)[0]\n",
    "    X_min = X[min_indices]\n",
    "    X_maj = X[maj_indices]\n",
    "    \n",
    "    ml = len(X_maj)\n",
    "    ms = len(X_min)\n",
    "    G = int((ml - ms) * beta)\n",
    "    print(f\"ProWSyn: G={G}, ml={ml}, ms={ms}, beta={beta}\")\n",
    "    \n",
    "    if G <= 0:\n",
    "        print(\"No synthetic samples needed (G <= 0). Returning original data.\")\n",
    "        return X, y\n",
    "    \n",
    "    P = X_min.copy()\n",
    "    partitions = []\n",
    "    proximity_levels = np.zeros(len(X_min))\n",
    "    \n",
    "    for i in range(L-1):\n",
    "        nn = NearestNeighbors(n_neighbors=min(K, len(P))).fit(P)\n",
    "        distances, indices = nn.kneighbors(X_maj)\n",
    "        Pi_indices = np.unique(indices.flatten())\n",
    "        Pi = P[Pi_indices]\n",
    "        partitions.append(Pi)\n",
    "        proximity_levels[Pi_indices] = i + 1\n",
    "        P = np.delete(P, Pi_indices, axis=0)\n",
    "    \n",
    "    if len(P) > 0:\n",
    "        partitions.append(P)\n",
    "        remaining_indices = np.where(proximity_levels == 0)[0]\n",
    "        proximity_levels[remaining_indices] = L\n",
    "    \n",
    "    weights = np.exp(-theta * (proximity_levels - 1))\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    synthetic_samples = []\n",
    "    for idx, x in enumerate(X_min):\n",
    "        gx = max(int(weights[idx] * G), 1)  # Ensure at least one sample per instance\n",
    "        for _ in range(gx):\n",
    "            y_idx = np.random.choice(len(X_min))\n",
    "            y_sample = X_min[y_idx]\n",
    "            alpha = np.random.uniform(0, 1)\n",
    "            s = x + alpha * (y_sample - x)\n",
    "            synthetic_samples.append(s)\n",
    "    \n",
    "    if not synthetic_samples:\n",
    "        print(\"No synthetic samples generated. Returning original data.\")\n",
    "        return X, y\n",
    "    \n",
    "    synthetic_samples = np.array(synthetic_samples)\n",
    "    if synthetic_samples.ndim == 1:\n",
    "        synthetic_samples = synthetic_samples.reshape(-1, X.shape[1])\n",
    "    \n",
    "    if synthetic_samples.shape[1] != X.shape[1]:\n",
    "        print(f\"Error: Mismatched dimensions - X shape: {X.shape}, synthetic_samples shape: {synthetic_samples.shape}\")\n",
    "        return X, y\n",
    "    \n",
    "    print(f\"Generated {len(synthetic_samples)} synthetic samples\")\n",
    "    X_synthetic = np.vstack([X, synthetic_samples])\n",
    "    y_synthetic = np.hstack([y, [minority_class] * len(synthetic_samples)])\n",
    "    \n",
    "    return X_synthetic, y_synthetic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "38a0b726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({np.int64(0): 500, np.int64(1): 268})\n",
      "ProWSyn: G=464, ml=500, ms=268, beta=2.0\n",
      "Generated 268 synthetic samples\n",
      "Balanced class distribution: Counter({np.int64(1): 536, np.int64(0): 500})\n"
     ]
    }
   ],
   "source": [
    "# Apply ProWSyn\n",
    "print(\"Original class distribution:\", Counter(y))\n",
    "X_balanced, y_balanced = prowsyn(X, y, beta=2.0, K=5, L=3, theta=0.5)\n",
    "y_balanced = y_balanced.astype(int)\n",
    "print(\"Balanced class distribution:\", Counter(y_balanced))\n",
    "\n",
    "# Verify sufficient samples for stratification\n",
    "min_samples_per_class = min(Counter(y_balanced).values())\n",
    "if min_samples_per_class < 10:\n",
    "    raise ValueError(f\"Insufficient samples ({min_samples_per_class}) for 10-fold stratification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d97445e6",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# Define Highway Layer\n",
    "class HighwayLayer(nn.Module):\n",
    "    \"\"\"Highway Layer for adaptive information flow\"\"\"\n",
    "    def __init__(self, units):\n",
    "        super(HighwayLayer, self).__init__()\n",
    "        self.transform_gate = nn.Linear(units, units)\n",
    "        self.transform = nn.Linear(units, units)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        T = self.sigmoid(self.transform_gate(x))\n",
    "        H = self.relu(self.transform(x))\n",
    "        C = 1.0 - T\n",
    "        return H * T + x * C\n",
    "\n",
    "# Define Highway Model\n",
    "class HighwayModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HighwayModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.highway1 = HighwayLayer(64)\n",
    "        self.highway2 = HighwayLayer(32)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.highway1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.highway2(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Define LeNet Model\n",
    "class LeNetModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LeNetModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 6, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(6, 16, kernel_size=5, padding=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=1)\n",
    "        self.conv3 = nn.Conv1d(16, 1, kernel_size=1)\n",
    "        self.fc1 = nn.Linear(input_dim, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.tanh(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.tanh(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.tanh(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.tanh(self.fc1(x))\n",
    "        x = self.tanh(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Define TCN Model\n",
    "class TCNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super(TCNLayer, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, \n",
    "                              padding=(kernel_size-1)*dilation, dilation=dilation)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class TCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=2, filters=32, kernel_size=3, dilation_base=2):\n",
    "        super(TCNModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_channels = 1 if i == 0 else filters\n",
    "            self.layers.append(TCNLayer(in_channels, filters, kernel_size, dilation_base**i))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(filters * input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Define Hi-Le Model\n",
    "class HiLeModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HiLeModel, self).__init__()\n",
    "        self.highway = HighwayModel(input_dim)\n",
    "        self.lenet = LeNetModel(input_dim)\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hwy_out = self.highway(x)\n",
    "        lenet_out = self.lenet(x)\n",
    "        combined = torch.cat([hwy_out, lenet_out], dim=1)\n",
    "        out = self.sigmoid(self.fc(combined))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ac5bc594",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training and Evaluation Functions\n",
    "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze()\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        scheduler.step(avg_loss)\n",
    "        if (epoch + 1) % 5 == 0:  # Log every 5 epochs\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor).squeeze()\n",
    "        preds = (outputs > 0.5).float().cpu().numpy()\n",
    "    return accuracy_score(y_test, preds), f1_score(y_test, preds, zero_division=0), \\\n",
    "           precision_score(y_test, preds, zero_division=0), recall_score(y_test, preds, zero_division=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0f4b554c",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/10\n",
      "Training HiLeModel\n",
      "Epoch 5/20, Avg Loss: 0.7012\n",
      "Epoch 10/20, Avg Loss: 0.6852\n",
      "Epoch 15/20, Avg Loss: 0.6647\n",
      "Epoch 20/20, Avg Loss: 0.6422\n",
      "HiLeModel Fold 1 - Accuracy: 0.5192, F1: 0.6835\n",
      "Training HighwayModel for fold 1\n",
      "Epoch 5/20, Avg Loss: 0.4854\n",
      "Epoch 10/20, Avg Loss: 0.4109\n",
      "Epoch 15/20, Avg Loss: 0.3817\n",
      "Epoch 20/20, Avg Loss: 0.3510\n",
      "Training LeNetModel for fold 1\n",
      "Epoch 5/20, Avg Loss: 0.4773\n",
      "Epoch 10/20, Avg Loss: 0.4482\n",
      "Epoch 15/20, Avg Loss: 0.4457\n",
      "Epoch 20/20, Avg Loss: 0.4411\n",
      "Training TCNModel for fold 1\n",
      "Warning: Skipping TCNModel due to shape mismatch in fold 1: mat1 and mat2 shapes cannot be multiplied (128x448 and 256x64)\n",
      "Meta-model input dimension: 2 for fold 1\n",
      "Training HiTCLe Meta-Model\n",
      "Epoch 5/20, Avg Loss: 0.6647\n",
      "Epoch 10/20, Avg Loss: 0.6325\n",
      "Epoch 15/20, Avg Loss: 0.5874\n",
      "Epoch 20/20, Avg Loss: 0.5377\n",
      "HiTCLe Fold 1 - Accuracy: 0.7596, F1: 0.8062\n",
      "\n",
      "Fold 2/10\n",
      "Training HiLeModel\n",
      "Epoch 5/20, Avg Loss: 0.6291\n",
      "Epoch 10/20, Avg Loss: 0.6093\n",
      "Epoch 15/20, Avg Loss: 0.5836\n",
      "Epoch 20/20, Avg Loss: 0.5686\n",
      "HiLeModel Fold 2 - Accuracy: 0.6827, F1: 0.7273\n",
      "Training HighwayModel for fold 2\n",
      "Epoch 5/20, Avg Loss: 0.4746\n",
      "Epoch 10/20, Avg Loss: 0.3904\n",
      "Epoch 15/20, Avg Loss: 0.3583\n",
      "Epoch 20/20, Avg Loss: 0.3278\n",
      "Training LeNetModel for fold 2\n",
      "Epoch 5/20, Avg Loss: 0.4429\n",
      "Epoch 10/20, Avg Loss: 0.4509\n",
      "Epoch 15/20, Avg Loss: 0.4365\n",
      "Epoch 20/20, Avg Loss: 0.4282\n",
      "Training TCNModel for fold 2\n",
      "Warning: Skipping TCNModel due to shape mismatch in fold 2: mat1 and mat2 shapes cannot be multiplied (128x448 and 256x64)\n",
      "Meta-model input dimension: 2 for fold 2\n",
      "Training HiTCLe Meta-Model\n",
      "Epoch 5/20, Avg Loss: 0.6802\n",
      "Epoch 10/20, Avg Loss: 0.6567\n",
      "Epoch 15/20, Avg Loss: 0.6241\n",
      "Epoch 20/20, Avg Loss: 0.5735\n",
      "HiTCLe Fold 2 - Accuracy: 0.7308, F1: 0.7586\n",
      "\n",
      "Fold 3/10\n",
      "Training HiLeModel\n",
      "Epoch 5/20, Avg Loss: 0.7046\n",
      "Epoch 10/20, Avg Loss: 0.6730\n",
      "Epoch 15/20, Avg Loss: 0.6492\n",
      "Epoch 20/20, Avg Loss: 0.6315\n",
      "HiLeModel Fold 3 - Accuracy: 0.4808, F1: 0.0000\n",
      "Training HighwayModel for fold 3\n",
      "Epoch 5/20, Avg Loss: 0.4869\n",
      "Epoch 10/20, Avg Loss: 0.4177\n",
      "Epoch 15/20, Avg Loss: 0.3844\n",
      "Epoch 20/20, Avg Loss: 0.3667\n",
      "Training LeNetModel for fold 3\n",
      "Epoch 5/20, Avg Loss: 0.5017\n",
      "Epoch 10/20, Avg Loss: 0.4493\n",
      "Epoch 15/20, Avg Loss: 0.4392\n",
      "Epoch 20/20, Avg Loss: 0.4271\n",
      "Training TCNModel for fold 3\n",
      "Warning: Skipping TCNModel due to shape mismatch in fold 3: mat1 and mat2 shapes cannot be multiplied (128x448 and 256x64)\n",
      "Meta-model input dimension: 2 for fold 3\n",
      "Training HiTCLe Meta-Model\n",
      "Epoch 5/20, Avg Loss: 0.6728\n",
      "Epoch 10/20, Avg Loss: 0.6450\n",
      "Epoch 15/20, Avg Loss: 0.6010\n",
      "Epoch 20/20, Avg Loss: 0.5372\n",
      "HiTCLe Fold 3 - Accuracy: 0.7885, F1: 0.8281\n",
      "\n",
      "Fold 4/10\n",
      "Training HiLeModel\n",
      "Epoch 5/20, Avg Loss: 0.6315\n",
      "Epoch 10/20, Avg Loss: 0.5805\n",
      "Epoch 15/20, Avg Loss: 0.5588\n",
      "Epoch 20/20, Avg Loss: 0.5356\n",
      "HiLeModel Fold 4 - Accuracy: 0.7885, F1: 0.8070\n",
      "Training HighwayModel for fold 4\n",
      "Epoch 5/20, Avg Loss: 0.4621\n",
      "Epoch 10/20, Avg Loss: 0.4218\n",
      "Epoch 15/20, Avg Loss: 0.3949\n",
      "Epoch 20/20, Avg Loss: 0.3843\n",
      "Training LeNetModel for fold 4\n",
      "Epoch 5/20, Avg Loss: 0.4818\n",
      "Epoch 10/20, Avg Loss: 0.4507\n",
      "Epoch 15/20, Avg Loss: 0.4522\n",
      "Epoch 20/20, Avg Loss: 0.4382\n",
      "Training TCNModel for fold 4\n",
      "Warning: Skipping TCNModel due to shape mismatch in fold 4: mat1 and mat2 shapes cannot be multiplied (128x448 and 256x64)\n",
      "Meta-model input dimension: 2 for fold 4\n",
      "Training HiTCLe Meta-Model\n",
      "Epoch 5/20, Avg Loss: 0.6683\n",
      "Epoch 10/20, Avg Loss: 0.6351\n",
      "Epoch 15/20, Avg Loss: 0.5826\n",
      "Epoch 20/20, Avg Loss: 0.5051\n",
      "HiTCLe Fold 4 - Accuracy: 0.7692, F1: 0.8095\n",
      "\n",
      "Fold 5/10\n",
      "Training HiLeModel\n",
      "Epoch 5/20, Avg Loss: 0.6442\n",
      "Epoch 10/20, Avg Loss: 0.6235\n",
      "Epoch 15/20, Avg Loss: 0.6050\n",
      "Epoch 20/20, Avg Loss: 0.5877\n",
      "HiLeModel Fold 5 - Accuracy: 0.7404, F1: 0.7477\n",
      "Training HighwayModel for fold 5\n",
      "Epoch 5/20, Avg Loss: 0.5035\n",
      "Epoch 10/20, Avg Loss: 0.3966\n",
      "Epoch 15/20, Avg Loss: 0.3760\n",
      "Epoch 20/20, Avg Loss: 0.3571\n",
      "Training LeNetModel for fold 5\n",
      "Epoch 5/20, Avg Loss: 0.4644\n",
      "Epoch 10/20, Avg Loss: 0.4497\n",
      "Epoch 15/20, Avg Loss: 0.4419\n",
      "Epoch 20/20, Avg Loss: 0.4276\n",
      "Training TCNModel for fold 5\n",
      "Warning: Skipping TCNModel due to shape mismatch in fold 5: mat1 and mat2 shapes cannot be multiplied (128x448 and 256x64)\n",
      "Meta-model input dimension: 2 for fold 5\n",
      "Training HiTCLe Meta-Model\n",
      "Epoch 5/20, Avg Loss: 0.6814\n",
      "Epoch 10/20, Avg Loss: 0.6650\n",
      "Epoch 15/20, Avg Loss: 0.6374\n",
      "Epoch 20/20, Avg Loss: 0.5974\n",
      "HiTCLe Fold 5 - Accuracy: 0.7692, F1: 0.8125\n",
      "\n",
      "Fold 6/10\n",
      "Training HiLeModel\n",
      "Epoch 5/20, Avg Loss: 0.6536\n",
      "Epoch 10/20, Avg Loss: 0.6280\n",
      "Epoch 15/20, Avg Loss: 0.6048\n",
      "Epoch 20/20, Avg Loss: 0.5942\n",
      "HiLeModel Fold 6 - Accuracy: 0.7885, F1: 0.7925\n",
      "Training HighwayModel for fold 6\n",
      "Epoch 5/20, Avg Loss: 0.4638\n",
      "Epoch 10/20, Avg Loss: 0.4167\n",
      "Epoch 15/20, Avg Loss: 0.3872\n",
      "Epoch 20/20, Avg Loss: 0.3699\n",
      "Training LeNetModel for fold 6\n",
      "Epoch 5/20, Avg Loss: 0.4725\n",
      "Epoch 10/20, Avg Loss: 0.4564\n",
      "Epoch 15/20, Avg Loss: 0.4441\n",
      "Epoch 20/20, Avg Loss: 0.4399\n",
      "Training TCNModel for fold 6\n",
      "Warning: Skipping TCNModel due to shape mismatch in fold 6: mat1 and mat2 shapes cannot be multiplied (128x448 and 256x64)\n",
      "Meta-model input dimension: 2 for fold 6\n",
      "Training HiTCLe Meta-Model\n",
      "Epoch 5/20, Avg Loss: 0.6853\n",
      "Epoch 10/20, Avg Loss: 0.6706\n",
      "Epoch 15/20, Avg Loss: 0.6502\n",
      "Epoch 20/20, Avg Loss: 0.6194\n",
      "HiTCLe Fold 6 - Accuracy: 0.7500, F1: 0.7969\n",
      "\n",
      "Fold 7/10\n",
      "Training HiLeModel\n",
      "Epoch 5/20, Avg Loss: 0.6238\n",
      "Epoch 10/20, Avg Loss: 0.5765\n",
      "Epoch 15/20, Avg Loss: 0.5466\n",
      "Epoch 20/20, Avg Loss: 0.5279\n",
      "HiLeModel Fold 7 - Accuracy: 0.7573, F1: 0.7706\n",
      "Training HighwayModel for fold 7\n",
      "Epoch 5/20, Avg Loss: 0.4583\n",
      "Epoch 10/20, Avg Loss: 0.3939\n",
      "Epoch 15/20, Avg Loss: 0.3582\n",
      "Epoch 20/20, Avg Loss: 0.3404\n",
      "Training LeNetModel for fold 7\n",
      "Epoch 5/20, Avg Loss: 0.4708\n",
      "Epoch 10/20, Avg Loss: 0.4504\n",
      "Epoch 15/20, Avg Loss: 0.4358\n",
      "Epoch 20/20, Avg Loss: 0.4306\n",
      "Training TCNModel for fold 7\n",
      "Warning: Skipping TCNModel due to shape mismatch in fold 7: mat1 and mat2 shapes cannot be multiplied (128x448 and 256x64)\n",
      "Meta-model input dimension: 2 for fold 7\n",
      "Training HiTCLe Meta-Model\n",
      "Epoch 5/20, Avg Loss: 0.6769\n",
      "Epoch 10/20, Avg Loss: 0.6556\n",
      "Epoch 15/20, Avg Loss: 0.6235\n",
      "Epoch 20/20, Avg Loss: 0.5758\n",
      "HiTCLe Fold 7 - Accuracy: 0.7476, F1: 0.7833\n",
      "\n",
      "Fold 8/10\n",
      "Training HiLeModel\n",
      "Epoch 5/20, Avg Loss: 0.6107\n",
      "Epoch 10/20, Avg Loss: 0.5671\n",
      "Epoch 15/20, Avg Loss: 0.5344\n",
      "Epoch 20/20, Avg Loss: 0.5163\n",
      "HiLeModel Fold 8 - Accuracy: 0.8252, F1: 0.8421\n",
      "Training HighwayModel for fold 8\n",
      "Epoch 5/20, Avg Loss: 0.4651\n",
      "Epoch 10/20, Avg Loss: 0.3973\n",
      "Epoch 15/20, Avg Loss: 0.3875\n",
      "Epoch 20/20, Avg Loss: 0.3410\n",
      "Training LeNetModel for fold 8\n",
      "Epoch 5/20, Avg Loss: 0.4782\n",
      "Epoch 10/20, Avg Loss: 0.4564\n",
      "Epoch 15/20, Avg Loss: 0.4447\n",
      "Epoch 20/20, Avg Loss: 0.4372\n",
      "Training TCNModel for fold 8\n",
      "Warning: Skipping TCNModel due to shape mismatch in fold 8: mat1 and mat2 shapes cannot be multiplied (128x448 and 256x64)\n",
      "Meta-model input dimension: 2 for fold 8\n",
      "Training HiTCLe Meta-Model\n",
      "Epoch 5/20, Avg Loss: 0.6749\n",
      "Epoch 10/20, Avg Loss: 0.6485\n",
      "Epoch 15/20, Avg Loss: 0.6081\n",
      "Epoch 20/20, Avg Loss: 0.5465\n",
      "HiTCLe Fold 8 - Accuracy: 0.8447, F1: 0.8689\n",
      "\n",
      "Fold 9/10\n",
      "Training HiLeModel\n",
      "Epoch 5/20, Avg Loss: 0.7119\n",
      "Epoch 10/20, Avg Loss: 0.6780\n",
      "Epoch 15/20, Avg Loss: 0.6448\n",
      "Epoch 20/20, Avg Loss: 0.6286\n",
      "HiLeModel Fold 9 - Accuracy: 0.5146, F1: 0.6795\n",
      "Training HighwayModel for fold 9\n",
      "Epoch 5/20, Avg Loss: 0.4820\n",
      "Epoch 10/20, Avg Loss: 0.4218\n",
      "Epoch 15/20, Avg Loss: 0.3817\n",
      "Epoch 20/20, Avg Loss: 0.3590\n",
      "Training LeNetModel for fold 9\n",
      "Epoch 5/20, Avg Loss: 0.4918\n",
      "Epoch 10/20, Avg Loss: 0.4720\n",
      "Epoch 15/20, Avg Loss: 0.4546\n",
      "Epoch 20/20, Avg Loss: 0.4541\n",
      "Training TCNModel for fold 9\n",
      "Warning: Skipping TCNModel due to shape mismatch in fold 9: mat1 and mat2 shapes cannot be multiplied (128x448 and 256x64)\n",
      "Meta-model input dimension: 2 for fold 9\n",
      "Training HiTCLe Meta-Model\n",
      "Epoch 5/20, Avg Loss: 0.6779\n",
      "Epoch 10/20, Avg Loss: 0.6536\n",
      "Epoch 15/20, Avg Loss: 0.6150\n",
      "Epoch 20/20, Avg Loss: 0.5592\n",
      "HiTCLe Fold 9 - Accuracy: 0.8155, F1: 0.8348\n",
      "\n",
      "Fold 10/10\n",
      "Training HiLeModel\n",
      "Epoch 5/20, Avg Loss: 0.5992\n",
      "Epoch 10/20, Avg Loss: 0.5634\n",
      "Epoch 15/20, Avg Loss: 0.5441\n",
      "Epoch 20/20, Avg Loss: 0.5242\n",
      "HiLeModel Fold 10 - Accuracy: 0.8641, F1: 0.8542\n",
      "Training HighwayModel for fold 10\n",
      "Epoch 5/20, Avg Loss: 0.4874\n",
      "Epoch 10/20, Avg Loss: 0.4233\n",
      "Epoch 15/20, Avg Loss: 0.4071\n",
      "Epoch 20/20, Avg Loss: 0.3871\n",
      "Training LeNetModel for fold 10\n",
      "Epoch 5/20, Avg Loss: 0.4746\n",
      "Epoch 10/20, Avg Loss: 0.4588\n",
      "Epoch 15/20, Avg Loss: 0.4550\n",
      "Epoch 20/20, Avg Loss: 0.4404\n",
      "Training TCNModel for fold 10\n",
      "Warning: Skipping TCNModel due to shape mismatch in fold 10: mat1 and mat2 shapes cannot be multiplied (128x448 and 256x64)\n",
      "Meta-model input dimension: 2 for fold 10\n",
      "Training HiTCLe Meta-Model\n",
      "Epoch 5/20, Avg Loss: 0.6767\n",
      "Epoch 10/20, Avg Loss: 0.6539\n",
      "Epoch 15/20, Avg Loss: 0.6205\n",
      "Epoch 20/20, Avg Loss: 0.5742\n",
      "HiTCLe Fold 10 - Accuracy: 0.8350, F1: 0.8496\n"
     ]
    }
   ],
   "source": [
    "# 10-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "metrics_hile = {'accuracy': [], 'f1': [], 'precision': [], 'recall': []}\n",
    "metrics_hitcle = {'accuracy': [], 'f1': [], 'precision': [], 'recall': []}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X_balanced, y_balanced)):\n",
    "    try:\n",
    "        print(f\"\\nFold {fold + 1}/10\")\n",
    "        X_train, X_test = X_balanced[train_idx], X_balanced[test_idx]\n",
    "        y_train, y_test = y_balanced[train_idx], y_balanced[test_idx]\n",
    "        \n",
    "        y_train = y_train.astype(int)\n",
    "        y_test = y_test.astype(int)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.1, stratify=y_train, random_state=42\n",
    "        )\n",
    "        \n",
    "        if len(X_train) == 0 or len(X_val) == 0 or len(X_test) == 0:\n",
    "            print(f\"Warning: Empty split in fold {fold + 1}. Skipping fold.\")\n",
    "            continue\n",
    "        \n",
    "        train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "        \n",
    "        # Train Hi-Le model\n",
    "        hile_model = HiLeModel(input_dim=X.shape[1]).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(hile_model.parameters(), lr=0.002)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "        print(\"Training HiLeModel\")\n",
    "        train_model(hile_model, train_loader, criterion, optimizer, scheduler, num_epochs=20)\n",
    "        \n",
    "        # Evaluate Hi-Le\n",
    "        acc, f1, prec, rec = evaluate_model(hile_model, X_test, y_test)\n",
    "        metrics_hile['accuracy'].append(acc)\n",
    "        metrics_hile['f1'].append(f1)\n",
    "        metrics_hile['precision'].append(prec)\n",
    "        metrics_hile['recall'].append(rec)\n",
    "        print(f\"HiLeModel Fold {fold + 1} - Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
    "        \n",
    "        # Train base models for HiTCLe\n",
    "        base_models = [\n",
    "            (HighwayModel(input_dim=X.shape[1]).to(device), \"HighwayModel\"),\n",
    "            (LeNetModel(input_dim=X.shape[1]).to(device), \"LeNetModel\"),\n",
    "            (TCNModel(input_dim=X.shape[1], filters=32).to(device), \"TCNModel\")\n",
    "        ]\n",
    "        \n",
    "        successful_models = []\n",
    "        base_preds_val = []\n",
    "        base_preds_test = []\n",
    "        \n",
    "        for model, model_name in base_models:\n",
    "            try:\n",
    "                print(f\"Training {model_name} for fold {fold + 1}\")\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "                scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "                train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=20)\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "                    test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "                    val_pred = model(val_tensor).squeeze().cpu().numpy()\n",
    "                    test_pred = model(test_tensor).squeeze().cpu().numpy()\n",
    "                    base_preds_val.append(val_pred)\n",
    "                    base_preds_test.append(test_pred)\n",
    "                successful_models.append(model)\n",
    "            except RuntimeError as e:\n",
    "                if \"mat1 and mat2 shapes cannot be multiplied\" in str(e):\n",
    "                    print(f\"Warning: Skipping {model_name} due to shape mismatch in fold {fold + 1}: {str(e)}\")\n",
    "                else:\n",
    "                    print(f\"Error training {model_name} in fold {fold + 1}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not successful_models:\n",
    "            print(f\"Error: No successful base models in fold {fold + 1}. Skipping HiTCLe evaluation.\")\n",
    "            continue\n",
    "        \n",
    "        base_preds_val = np.column_stack(base_preds_val)\n",
    "        base_preds_test = np.column_stack(base_preds_test)\n",
    "        \n",
    "        # Verify predictions\n",
    "        if base_preds_val.shape[1] == 0 or base_preds_test.shape[1] == 0:\n",
    "            print(f\"Error: Empty predictions in fold {fold + 1}. Skipping HiTCLe evaluation.\")\n",
    "            continue\n",
    "        \n",
    "        # Train meta-model for HiTCLe\n",
    "        meta_input_dim = len(successful_models)  # Number of successful base models\n",
    "        print(f\"Meta-model input dimension: {meta_input_dim} for fold {fold + 1}\")\n",
    "        meta_model = HighwayModel(input_dim=meta_input_dim).to(device)\n",
    "        optimizer = optim.Adam(meta_model.parameters(), lr=0.002)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "        meta_dataset = TensorDataset(torch.FloatTensor(base_preds_val), torch.FloatTensor(y_val))\n",
    "        meta_loader = DataLoader(meta_dataset, batch_size=128, shuffle=True)\n",
    "        print(\"Training HiTCLe Meta-Model\")\n",
    "        train_model(meta_model, meta_loader, criterion, optimizer, scheduler, num_epochs=20)\n",
    "        \n",
    "        # Evaluate HiTCLe\n",
    "        meta_model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_tensor = torch.FloatTensor(base_preds_test).to(device)\n",
    "            outputs = meta_model(test_tensor).squeeze()\n",
    "            preds = (outputs > 0.5).float().cpu().numpy()\n",
    "        \n",
    "        acc, f1, prec, rec = accuracy_score(y_test, preds), f1_score(y_test, preds, zero_division=0), \\\n",
    "                             precision_score(y_test, preds, zero_division=0), recall_score(y_test, preds, zero_division=0)\n",
    "        metrics_hitcle['accuracy'].append(acc)\n",
    "        metrics_hitcle['f1'].append(f1)\n",
    "        metrics_hitcle['precision'].append(prec)\n",
    "        metrics_hitcle['recall'].append(rec)\n",
    "        print(f\"HiTCLe Fold {fold + 1} - Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in fold {fold + 1}: {str(e)}. Skipping fold.\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "90944925",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check if any folds were successful\n",
    "if not metrics_hile['accuracy']:\n",
    "    raise ValueError(\"No successful folds completed. Check data or StratifiedKFold configuration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8a99b07e",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hi-Le Model Average Metrics (10-Fold CV):\n",
      "Accuracy: 0.6961 ± 0.1336\n",
      "F1: 0.6904 ± 0.2370\n",
      "Precision: 0.6510 ± 0.2507\n",
      "Recall: 0.7657 ± 0.2696\n",
      "\n",
      "HiTCLe Model Average Metrics (10-Fold CV):\n",
      "Accuracy: 0.7810 ± 0.0368\n",
      "F1: 0.8148 ± 0.0305\n",
      "Precision: 0.7263 ± 0.0372\n",
      "Recall: 0.9309 ± 0.0514\n",
      "Epoch 5/20, Avg Loss: 0.6296\n",
      "Epoch 10/20, Avg Loss: 0.6009\n",
      "Epoch 15/20, Avg Loss: 0.5849\n",
      "Epoch 20/20, Avg Loss: 0.5561\n",
      "Epoch 5/20, Avg Loss: 0.4782\n",
      "Epoch 10/20, Avg Loss: 0.3826\n",
      "Epoch 15/20, Avg Loss: 0.4150\n",
      "Epoch 20/20, Avg Loss: 0.3821\n",
      "Epoch 5/20, Avg Loss: 0.4987\n",
      "Epoch 10/20, Avg Loss: 0.4240\n",
      "Epoch 15/20, Avg Loss: 0.4372\n",
      "Epoch 20/20, Avg Loss: 0.4597\n",
      "Warning: Excluding TCNModel from LIME analysis due to shape mismatch. Continuing with other models.\n",
      "Epoch 5/20, Avg Loss: 0.4437\n",
      "Epoch 10/20, Avg Loss: 0.3682\n",
      "Epoch 15/20, Avg Loss: 0.3542\n",
      "Epoch 20/20, Avg Loss: 0.3620\n",
      "Models saved to model.pkl\n"
     ]
    }
   ],
   "source": [
    "# # Compute average metrics\n",
    "# print(\"\\nHi-Le Model Average Metrics (10-Fold CV):\")\n",
    "# for metric, values in metrics_hile.items():\n",
    "#     print(f\"{metric.capitalize()}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "# print(\"\\nHiTCLe Model Average Metrics (10-Fold CV):\")\n",
    "# for metric, values in metrics_hitcle.items():\n",
    "#     print(f\"{metric.capitalize()}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "# # LIME Analysis for Hi-Le Model\n",
    "# hile_model = HiLeModel(input_dim=X.shape[1]).to(device)\n",
    "# train_dataset = TensorDataset(torch.FloatTensor(X_balanced), torch.FloatTensor(y_balanced))\n",
    "# train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "# train_model(hile_model, train_loader, nn.BCELoss(), optim.Adam(hile_model.parameters(), lr=0.002), \n",
    "#             optim.lr_scheduler.ReduceLROnPlateau(optim.Adam(hile_model.parameters(), lr=0.002), mode='min', factor=0.5, patience=3), num_epochs=20)\n",
    "\n",
    "# def hile_predict_proba(X):\n",
    "#     hile_model.eval()\n",
    "#     X_tensor = torch.FloatTensor(X).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = hile_model(X_tensor).squeeze().cpu().numpy()\n",
    "#     if outputs.ndim == 0:\n",
    "#         outputs = np.array([outputs])\n",
    "#     return np.column_stack([1 - outputs, outputs])\n",
    "\n",
    "# explainer = LimeTabularExplainer(\n",
    "#     training_data=X_balanced,\n",
    "#     feature_names=columns[:-1],\n",
    "#     class_names=['Non-Diabetic', 'Diabetic'],\n",
    "#     mode='classification'\n",
    "# )\n",
    "\n",
    "# np.random.seed(42)\n",
    "# sample_idx = np.random.randint(0, len(X_balanced))\n",
    "# exp = explainer.explain_instance(\n",
    "#     data_row=X_balanced[sample_idx],\n",
    "#     predict_fn=hile_predict_proba,\n",
    "#     num_features=8\n",
    "# )\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# exp.as_pyplot_figure()\n",
    "# plt.title(f\"LIME Explanation for Hi-Le Model (Instance {sample_idx})\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"lime_hile.png\")\n",
    "\n",
    "# # LIME Analysis for HiTCLe Model\n",
    "# base_models = [\n",
    "#     (HighwayModel(input_dim=X.shape[1]).to(device), \"HighwayModel\"),\n",
    "#     (LeNetModel(input_dim=X.shape[1]).to(device), \"LeNetModel\"),\n",
    "#     (TCNModel(input_dim=X.shape[1], filters=32).to(device), \"TCNModel\")\n",
    "# ]\n",
    "# successful_base_models = []\n",
    "\n",
    "# for model, model_name in base_models:\n",
    "#     try:\n",
    "#         train_model(model, train_loader, nn.BCELoss(), optim.Adam(model.parameters(), lr=0.002), \n",
    "#                     optim.lr_scheduler.ReduceLROnPlateau(optim.Adam(model.parameters(), lr=0.002), mode='min', factor=0.5, patience=3), num_epochs=20)\n",
    "#         successful_base_models.append(model)\n",
    "#     except RuntimeError as e:\n",
    "#         if \"mat1 and mat2 shapes cannot be multiplied\" in str(e):\n",
    "#             print(f\"Warning: Excluding {model_name} from LIME analysis due to shape mismatch. Continuing with other models.\")\n",
    "#         else:\n",
    "#             raise e\n",
    "\n",
    "# meta_input_dim = len(successful_base_models)\n",
    "# meta_model = HighwayModel(input_dim=meta_input_dim).to(device)\n",
    "# base_preds = np.column_stack([\n",
    "#     model(torch.FloatTensor(X_balanced).to(device)).squeeze().cpu().detach().numpy()\n",
    "#     for model in successful_base_models\n",
    "# ])\n",
    "# meta_dataset = TensorDataset(torch.FloatTensor(base_preds), torch.FloatTensor(y_balanced))\n",
    "# meta_loader = DataLoader(meta_dataset, batch_size=128, shuffle=True)\n",
    "# train_model(meta_model, meta_loader, nn.BCELoss(), optim.Adam(meta_model.parameters(), lr=0.002), \n",
    "#             optim.lr_scheduler.ReduceLROnPlateau(optim.Adam(meta_model.parameters(), lr=0.002), mode='min', factor=0.5, patience=3), num_epochs=20)\n",
    "\n",
    "# def hitcle_predict_proba(X):\n",
    "#     base_preds = np.column_stack([\n",
    "#         model(torch.FloatTensor(X).to(device)).squeeze().cpu().detach().numpy()\n",
    "#         for model in successful_base_models\n",
    "#     ])\n",
    "#     meta_model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         outputs = meta_model(torch.FloatTensor(base_preds).to(device)).squeeze().cpu().numpy()\n",
    "#     if outputs.ndim == 0:\n",
    "#         outputs = np.array([outputs])\n",
    "#     return np.column_stack([1 - outputs, outputs])\n",
    "\n",
    "# exp_hitcle = explainer.explain_instance(\n",
    "#     data_row=X_balanced[sample_idx],\n",
    "#     predict_fn=hitcle_predict_proba,\n",
    "#     num_features=8\n",
    "# )\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# exp_hitcle.as_pyplot_figure()\n",
    "# plt.title(f\"LIME Explanation for HiTCLe Model (Instance {sample_idx})\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"lime_hitcle.png\")\n",
    "\n",
    "# # Plot model performance comparison\n",
    "# epochs = [5, 10, 20]\n",
    "# hile_acc = [np.mean(metrics_hile['accuracy'])] * len(epochs)\n",
    "# hitcle_acc = [np.mean(metrics_hitcle['accuracy'])] * len(epochs)\n",
    "# plt.figure()\n",
    "# plt.plot(epochs, hile_acc, label='Hi-Le', marker='o')\n",
    "# plt.plot(epochs, hitcle_acc, label='HiTCLe', marker='s')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Model Performance Comparison')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.savefig(\"performance_comparison.png\")\n",
    "# Compute average metrics\n",
    "# Compute average metrics\n",
    "# Compute average metrics\n",
    "print(\"\\nHi-Le Model Average Metrics (10-Fold CV):\")\n",
    "for metric, values in metrics_hile.items():\n",
    "    print(f\"{metric.capitalize()}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "print(\"\\nHiTCLe Model Average Metrics (10-Fold CV):\")\n",
    "for metric, values in metrics_hitcle.items():\n",
    "    print(f\"{metric.capitalize()}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "# LIME Analysis for Hi-Le Model\n",
    "hile_model = HiLeModel(input_dim=X.shape[1]).to(device)\n",
    "train_dataset = TensorDataset(torch.FloatTensor(X_balanced), torch.FloatTensor(y_balanced))\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "train_model(hile_model, train_loader, nn.BCELoss(), optim.Adam(hile_model.parameters(), lr=0.002), \n",
    "            optim.lr_scheduler.ReduceLROnPlateau(optim.Adam(hile_model.parameters(), lr=0.002), mode='min', factor=0.5, patience=3), num_epochs=20)\n",
    "\n",
    "def hile_predict_proba(X):\n",
    "    hile_model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = hile_model(X_tensor).squeeze().cpu().numpy()\n",
    "    if outputs.ndim == 0:\n",
    "        outputs = np.array([outputs])\n",
    "    return np.column_stack([1 - outputs, outputs])\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_balanced,\n",
    "    feature_names=columns[:-1],\n",
    "    class_names=['Non-Diabetic', 'Diabetic'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_idx = np.random.randint(0, len(X_balanced))\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=X_balanced[sample_idx],\n",
    "    predict_fn=hile_predict_proba,\n",
    "    num_features=8\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "exp.as_pyplot_figure()\n",
    "plt.title(f\"LIME Explanation for Hi-Le Model (Instance {sample_idx})\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"lime_hile.png\")\n",
    "\n",
    "# LIME Analysis for HiTCLe Model\n",
    "base_models = [\n",
    "    (HighwayModel(input_dim=X.shape[1]).to(device), \"HighwayModel\"),\n",
    "    (LeNetModel(input_dim=X.shape[1]).to(device), \"LeNetModel\"),\n",
    "    (TCNModel(input_dim=X.shape[1], filters=32).to(device), \"TCNModel\")\n",
    "]\n",
    "successful_base_models = []\n",
    "\n",
    "for model, model_name in base_models:\n",
    "    try:\n",
    "        train_model(model, train_loader, nn.BCELoss(), optim.Adam(model.parameters(), lr=0.002), \n",
    "                    optim.lr_scheduler.ReduceLROnPlateau(optim.Adam(model.parameters(), lr=0.002), mode='min', factor=0.5, patience=3), num_epochs=20)\n",
    "        successful_base_models.append(model)\n",
    "    except RuntimeError as e:\n",
    "        if \"mat1 and mat2 shapes cannot be multiplied\" in str(e):\n",
    "            print(f\"Warning: Excluding {model_name} from LIME analysis due to shape mismatch. Continuing with other models.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "meta_input_dim = len(successful_base_models)\n",
    "meta_model = HighwayModel(input_dim=meta_input_dim).to(device)\n",
    "base_preds = np.column_stack([\n",
    "    model(torch.FloatTensor(X_balanced).to(device)).squeeze().cpu().detach().numpy()\n",
    "    for model in successful_base_models\n",
    "])\n",
    "meta_dataset = TensorDataset(torch.FloatTensor(base_preds), torch.FloatTensor(y_balanced))\n",
    "meta_loader = DataLoader(meta_dataset, batch_size=128, shuffle=True)\n",
    "train_model(meta_model, meta_loader, nn.BCELoss(), optim.Adam(meta_model.parameters(), lr=0.002), \n",
    "            optim.lr_scheduler.ReduceLROnPlateau(optim.Adam(meta_model.parameters(), lr=0.002), mode='min', factor=0.5, patience=3), num_epochs=20)\n",
    "\n",
    "def hitcle_predict_proba(X):\n",
    "    base_preds = np.column_stack([\n",
    "        model(torch.FloatTensor(X).to(device)).squeeze().cpu().detach().numpy()\n",
    "        for model in successful_base_models\n",
    "    ])\n",
    "    meta_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = meta_model(torch.FloatTensor(base_preds).to(device)).squeeze().cpu().numpy()\n",
    "    if outputs.ndim == 0:\n",
    "        outputs = np.array([outputs])\n",
    "    return np.column_stack([1 - outputs, outputs])\n",
    "\n",
    "exp_hitcle = explainer.explain_instance(\n",
    "    data_row=X_balanced[sample_idx],\n",
    "    predict_fn=hitcle_predict_proba,\n",
    "    num_features=8\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "exp_hitcle.as_pyplot_figure()\n",
    "plt.title(f\"LIME Explanation for HiTCLe Model (Instance {sample_idx})\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"lime_hitcle.png\")\n",
    "\n",
    "# Plot model performance comparison\n",
    "epochs = [5, 10, 20]\n",
    "hile_acc = [np.mean(metrics_hile['accuracy'])] * len(epochs)\n",
    "hitcle_acc = [np.mean(metrics_hitcle['accuracy'])] * len(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs, hile_acc, label='Hi-Le', marker='o')\n",
    "plt.plot(epochs, hitcle_acc, label='HiTCLe', marker='s')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"performance_comparison.png\")\n",
    "import pickle\n",
    "model_save_path = \"model.pkl\"\n",
    "model_data = {\n",
    "    \"input_dim\": X.shape[1],\n",
    "    \"meta_input_dim\": meta_input_dim,\n",
    "    \"hile_state_dict\": hile_model.state_dict(),\n",
    "    \"hitcle_base_state_dicts\": [(model.state_dict(), model.__class__.__name__) for model in successful_base_models],\n",
    "    \"hitcle_meta_state_dict\": meta_model.state_dict()\n",
    "}\n",
    "with open(model_save_path, \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "print(f\"Models saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcf42d8",
   "metadata": {},
   "source": [
    "import pickle\n",
    "model_save_path = \"model.pkl\"\n",
    "model_data = {\n",
    "    \"input_dim\": X.shape[1],\n",
    "    \"meta_input_dim\": meta_input_dim,\n",
    "    \"hile_state_dict\": hile_model.state_dict(),\n",
    "    \"hitcle_base_state_dicts\": [(model.state_dict(), model.__class__.__name__) for model in successful_base_models],\n",
    "    \"hitcle_meta_state_dict\": meta_model.state_dict()\n",
    "}\n",
    "with open(model_save_path, \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "print(f\"Models saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
